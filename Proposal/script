1. NFL
https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-analytics
2. NBA Draft
https://www.kaggle.com/datasets/mattop/nba-draft-basketball-player-data-19892021
3. make data count
https://www.kaggle.com/competitions/make-data-count-finding-data-references


1. NBA draft
我们首先关注NBA选秀的数据。这个数据集包含了从1989年到2021年全部NBA新秀的数据，分为了'id', 'year', 'rank', 'overall_pick', 'team', 'player', 'college',
'years_active', 'games', 'minutes_played', 'points', 'total_rebounds','assists', 'field_goal_percentage', '3_point_percentage',
'free_throw_percentage', 'average_minutes_played', 'points_per_game','average_total_rebounds', 'average_assists', 'win_shares',
'win_shares_per_48_minutes', 'box_plus_minus','value_over_replacement'这些维度。

我们的目标是从这个数据集中通过分析球员前五年的box score，结合其顺位、出身大学和所在球队刻画出这个球员的潜力以及在联盟中的兑现程度（也就是发展路径），
我们期望可以得到类似“超级新星”，“高开低走”和“默默无闻”等形状良好的簇。考虑到这种统计方式对于2017年之后的球员并不公平，因为他们实际上真正被选入联盟都没有够5年，
因此我们决定使用1989-2017的数据来训练我们的模型，并直接使用2017年之后的新秀的数据作为模型泛化性能和稳定性能的考察。我们还期望使用这个模型来选出各个类型的球员的模板作为展示。

我们这个项目的新颖之处在于以下几处：首先是这个数据集本身，它是三年前发布的数据集，很新颖，而且在kaggle上目前仍然只有四个用户对其进行了公开的讨论，而且绝大多数都只是EDA，并没有像我们这样
真正利用了数据进行建模分析的；其次是我们使用的模型，我们期望在这个数据集上应用较为新颖的模型，但是我们目前尚未进行实际探索，并不知道哪个模型才是真正好的，我们计划使用多种聚类方法，
然后通过结合主观的判断以及量化标准进行最终的选择；最后是我们的思想，自我接触篮球开始，联盟在近20年的时间里通过各种量化指标对球员进行了无微不至的分析，试图将他们解构，而却从未有
任何分析师试图分析这个球员在自己职业路径上的探索和自我价值的实现，我们试图通过自己的研究，将到目前为止仍旧孤立的篮球数据分析方法进行革新，通过使用无监督学习的方式将球员的数据有机的结合起来。

我们这个数据集比较小,只有212.4 kb，但是又不够小到我们能确定其会展现出好看的结果，从可行性上说这个数据是最好的，但是我们还有两个使用更大的数据集的idea，我们仍在纠结当中，希望可以得到您的帮助和意见。

2. NFL Big Bowl
我们还找了NFL的数据，这个数据来自于kaggle的NFL Big Data Bowl 2026 - Analytics,数据里包含了非常多的内容，包括每场比赛的数据、每场比赛每个play的数据以及所有球员的数据，以及最重要的视频帧的数据，
这是一个非常庞大的数据集，不过我们并不打算直接利用它，也不会参与kaggle的比赛。

对于这个项目我们有两个层次的视角可以进行研究，一个是从队伍的角度，通过分析在不同的play下球队的站位和战术，从较为宏观的角度分析不同的队伍的比赛风格；另一个角度是从每场比赛的角度，分析不同队伍的不同wr和qb的个人比赛风格，
比如马霍姆斯倾向于传出怎样的球，以及不同的wr在跑战术时的风格。我们这个项目的数据集本身就天然的具备novelty，因为这个是对2026年超级碗比赛的预测准备的数据集，是最新的；另外用这个数据集进行聚类分析的更是几乎没有，我们
期望能从中聚类出各具代表性的球员或球队，从而帮助观众更好地理解比赛内容以及球队或球员的比赛风格，也可以帮助从业者们从一个新颖的角度审视比赛。

但是问题在于这个数据过于庞大，我们很难对结果进行把控，甚至对于结果的解释都有可能存在较大的问题，但是好处也在于此，如果做出结果来应该是最有insight的数据。另外我们并不知道该从球队的视角进行分析更具可行性，还是从球员的
角度更具可行性，我们希望可以从您那边得到宝贵的建议。

3. Make Data Count

我们关注 “Make Data Count” 数据集。该数据集包含公开学术论文的基本信息、引用方式标签及原文件（.pdf/.xml）。我们不打算直接使用其中的 “primary/secondary” 标签，而是希望通过分析论文内容和引用关系，无监督地发现学术研究中的潜在模式与趋势。
具体而言，我们将从 PDF/XML 中抽取 论文节点、数据集节点与引用上下文节点，规范化 DOI、标题和数据集名称，构建“论文–引用–数据集”三元关系图谱。节点特征将由 BERT 等模型生成高维语义嵌入，边权则通过文本向量间的语义相似度进行衡量。我们计划使用 图神经网络（GNN） 等方法对该图谱进行分析，以挖掘潜在模式，获得社区聚类的主题与引用模式，从而帮助研究者更好地理解学术研究中的数据集使用与引用行为。

本项目的创新在于，一方面探索 无监督学习 在这一新型学术数据集上的潜力，另一方面结合 文本语义与引用关系 构建更丰富的学术知识图谱。这种图谱不仅能揭示显性的引用结构，也有助于识别隐含的学术关联与数据复用模式。

目前我们仍在评估项目的可行性。我们对 知识图谱构建与社区发现方法 尚不熟悉，将该任务与以往的聚类经验结合可能存在一定挑战。此外，由于数据集缺乏明确的结构化特征，我们需要依赖大规模 NLP 模型 提取语义特征，这在数据预处理和词嵌入阶段都可能遇到技术与计算上的困难。

We focus on the “Make Data Count” dataset, which contains basic information on publicly available academic papers, citation type labels, and the original files (.pdf/.xml). We do not intend to directly use the “primary/secondary” labels provided in the dataset. Instead, we aim to analyze the content and citation relationships of papers to discover, in an unsupervised manner, the underlying patterns and trends in academic research. Specifically, we will extract paper nodes, dataset nodes, and citation context nodes from the PDF/XML files, normalize the DOI, titles, and dataset names, and construct a “paper–citation–dataset” tripartite relational graph. Node features will be generated using high-dimensional semantic embeddings from models such as BERT, while edge weights will be measured through the semantic similarity between text vectors. We plan to apply Graph Neural Network (GNN) methods to analyze this graph, uncover latent patterns, identify community-level topics and citation behaviors, and thereby help researchers better understand dataset usage and citation practices in academic research.

The novelty of this project lies in two aspects. First, it explores the potential of unsupervised learning on this new type of academic dataset. Second, it combines textual semantics and citation relationships to build a richer academic knowledge graph. Such a graph can reveal explicit citation structures as well as identify implicit scholarly connections and data reuse patterns.

We are still evaluating the feasibility of this project. We are not yet familiar with knowledge graph construction and community detection methods, and integrating these tasks with our previous experience in clustering may present certain challenges. Furthermore, since the dataset lacks explicit structured features, we need to rely on large-scale NLP models to extract semantic representations, which may pose technical and computational challenges during data preprocessing and embedding generation.
